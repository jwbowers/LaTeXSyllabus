%% add criteria for grading, change due dates for papers.
\immediate\write18{sh ./vc}
\documentclass[10pt]{article}
\input{vc}
\usepackage{graphicx,parskip}
\usepackage[T1]{fontenc} \usepackage{textcomp}
%% \renewcommand{\rmdefault}{pmnj}
%% \renewcommand{\sfdefault}{phv} %helvetica
\usepackage{tgpagella}
\usepackage[sc]{mathpazo}
\renewcommand*{\bfdefault}{bx} 
\renewcommand{\oldstylenums}[1]{%
  {\fontfamily{pplj}\selectfont #1}} 
\usepackage{microtype}

\hyphenation{Incomplete}

\usepackage{bibentry,natbib,url,comment,amsmath}
% \usepackage[bookmarks,pdftex,letterpaper]{hyperref}
\bibliographystyle{apalike}
% \renewcommand\harvardurl[1]{\textsf{\textbf{url:}} \url{#1}}
% \urlstyle{rm} parskip.sty does next two lines better
% \setlength{\parindent}{0pt} \addtolength{\parskip}{.5\baselineskip}
\usepackage[letterpaper,bottom=.75in,top=1in,right=1in,lmargin=1.15in]{geometry}

\usepackage{advdate}

\usepackage[compact,nobottomtitles*]{titlesec} %nobottomtitles
\titleformat{\part}[hang]{\large\scshape}{\hspace{-.75in}\thepart}{.5em}{}{}
\titleformat{\section}[hang]{\large\bfseries}{\hspace{-.75in}\thesection}{.5em}{}{}
\titleformat{\subsection}[leftmargin]{\small\bfseries\filleft}{\thesubsection}{.5em}{\hspace{-.75in}}{}
\titleformat{\subsubsection}[leftmargin]{\itshape\filleft}{\thesubsubsection}{.2em}{\hspace{-.75in}}{}
\titleformat{\paragraph}[runin]{\bfseries}{\theparagraph}{0em}{}{}

\titlespacing{\part}{0ex}{.5ex plus .1ex minus .2ex}{-.25\parskip}
\titlespacing{\section}{0ex}{1.5ex plus .1ex minus .2ex}{-.25\parskip}
\titlespacing{\subsection}{0ex}{.5ex plus .1ex minus .1ex}{1ex}
\titlespacing{\subsubsection}{0ex}{.5ex plus .1ex minus .1ex}{1ex}
\titlespacing{\paragraph}{0em}{1ex}{.5ex plus .1ex minus .1ex}


% \titleformat{\section}[hang]{\large\bfseries}{\hspace{-.75in}\thesection}{.5em}{}{}
% \titleformat*{\section}{\hspace{-.75in}}
% \titleformat{\subsection}[hang]{\bfseries}{\thesubsection}{.5em}{}{}
% \titleformat{\subsection}[leftmargin]{\small\bfseries\filleft}{\thesubsection}{.5em}{\hspace{-.75in}}{}
% \titleformat{\subsubsection}[leftmargin]{\itshape\filleft}{\thesubsubsection}{.2em}{\hspace{-.75in}}{}
% \titleformat{\paragraph}[runin]{\bfseries}{\theparagraph}{0em}{}{}

% \titlespacing{\section}{2pc}{1.5ex plus .1ex minus .2ex}{1pc}
% \titlespacing{\subsection}{0pt}{1pt}{1pt}
% \titlespacing{\paragraph}{0em}{1ex}{2ex}
% \titlespacing{\subsection}{2pc}{1.5ex plus .1ex minus .2ex}{1pc}
% \titlespacing{\subsubsection}{2pc}{1.5ex plus .1ex minus .2ex}{1pc}

% \setcounter{secnumdepth}{0}


\newenvironment{introstuff} {\setcounter{secnumdepth}{0}%
  \titlespacing*{\section}{-.75in}{1em}{0em}{}%
  \titleformat{\subsection}[leftmargin]{\itshape\filleft}{\thesubsection}{.5em}{\hspace{-.75in}}{}%
  \titleformat{\subsubsection}[leftmargin]{\itshape\filleft}{\thesubsubsection}{.2em}{\hspace{-.75in}}{}%
  \titleformat{\paragraph}[hang]{\bfseries}{\theparagraph}{0em}{}{}%
  \titlespacing{\subsection}{2pc}{1.5ex plus .1ex minus .2ex}{1pc}%
  \titlespacing{\paragraph}{0em}{1ex}{0ex plus .1ex minus .1ex}%
  \titlespacing{\subsubsection}{2pc}{1.5ex plus .1ex minus .2ex}{1pc}%
} {\setcounter{secnumdepth}{0}%
  \titleformat{\part}[hang]{\large\bfseries}{\hspace{-.75in}\thepart}{.5em}{}{}%
  \titleformat{\section}[hang]{\large\bfseries}{\hspace{-.75in}\thesection}{.5em}{}{}%
  \titleformat{\subsection}[leftmargin]{\small\bfseries\filleft}{\thesubsection}{.5em}{\hspace{-.75in}}{}%
  \titleformat{\subsubsection}[leftmargin]{\itshape\filleft}{\thesubsubsection}{.2em}{\hspace{-.75in}}{}%
  \titleformat{\paragraph}[runin]{\bfseries}{\theparagraph}{0em}{}{}%
  % \titleformat{\subsection}[hang]{\itshape}{\thesubsection}{.5em}{}{}%
  \titlespacing{\section}{2pc}{1.5ex plus .1ex minus .2ex}{1pc}%
  \titlespacing{\paragraph}{0em}{1ex}{0ex plus .1ex minus .1ex}%
  \titlespacing{\subsubsection}{2pc}{1.5ex plus .1ex minus .2ex}{1pc}%
}

% Create new title appearance
\makeatletter
\def\maketitle{%
  %\null
  \thispagestyle{empty}%
  \begin{center}\leavevmode
    \normalfont
    {\large \bfseries\@title\par}%
    {\large \@author\par}%
    {\large \@date\par}%
  \end{center}%
  \null }
\makeatother

\usepackage{fancyhdr}
% \renewcommand{\sectionmark}[1]{\markright{#1}{}}
  
\fancypagestyle{myfancy}{%
  \fancyhf{}
  % \fancyhead[R]{\small{Page~\thepage}}
  \fancyhead[R]{\small{PS 531 -- Spring 2010 -- \thepage}}
  \fancyfoot[R]{\footnotesize{Rev: \VCRevision~on~\VCDateTEX}}
  % \fancyfoot[R]{\small{\today -- Jake Bowers}}
  \renewcommand{\headrulewidth}{0pt}
  \renewcommand{\footrulewidth}{0pt}}

\pagestyle{myfancy}

\newcommand{\entrylabel}[1]{\mbox{\textsf{#1:}}\hfil}


%% These next lines tell latex that it is ok to have a single graphic
%% taking up most of a page, and they also decrease the space arou
%% figures and tables.
\renewcommand\floatpagefraction{.9} \renewcommand\topfraction{.9}
\renewcommand\bottomfraction{.9} \renewcommand\textfraction{.1}
\setcounter{totalnumber}{50} \setcounter{topnumber}{50}
\setcounter{bottomnumber}{50} \setlength{\intextsep}{2ex}
\setlength{\floatsep}{2ex} \setlength{\textfloatsep}{2ex}

\newenvironment{entry} {\begin{list}{}%
    {\renewcommand{\makelabel}{\entrylabel}%
      \setlength{\labelwidth}{1in}% \setlength{\labelwidth}{35pt}%
      \setlength{\leftmargin}{\labelwidth+\labelsep}%
    }%
  }%
  {\end{list}}

\newenvironment{Ventry}[1]%
{\begin{list}{}{\renewcommand{\makelabel}[1]{\textbf{##1:}\hfil}%
      \settowidth{\labelwidth}{\textbf{#1~:}}%
      \setlength{\leftmargin}{\labelwidth+\labelsep}}}%
  {\end{list}}

\newcommand{\Mentrylabel}[1]%
{\raisebox{0pt}[1em][0pt]{\makebox[\labelwidth][l]%
    {\parbox[t]{\labelwidth}{\hspace{0pt}\textsf{#1:}}}}}

\newenvironment{Mentry}%
{\renewcommand{\entrylabel}{\Mentrylabel}\begin{entry}}%
  {\end{entry}}


\specialcomment{com} {\begingroup\sffamily\small\bfseries}{\endgroup}
\excludecomment{com}

\title{Political Science 531 \\ Quantitative Political Analysis II \\
  Linear Models and Statistical Inference}
\author{Jake Bowers \\
  \small{jwbowers@illinois.edu \\
    Moodle:
    \url{http://cho.pol.uiuc.edu/moodle/course/view.php?id=7}}}

\date{Spring 2011}%, \SVNDate, Version \SVNRev}

\usepackage[pdftex,colorlinks=TRUE,citecolor=blue]{hyperref}

\renewcommand{\bibname}{ }
% \renewcommand{\refname}{\normalsize{Required:}}
\renewcommand{\refname}{\vspace{-2em}}

\def\themonth{\ifcase\month\or
  January\or February\or March\or April\or May\or June\or
  July\or August\or September\or October\or November\or December\fi} 

%Math defs
\newcommand{\bX}{\mathbf{X}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bY}{\mathbf{Y}}
\newcommand{\bbeta}{\boldsymbol{\beta}}


\begin{document}
\maketitle

\begin{introstuff}
  \section{General Information}
Moodle enrollment key: ps531. I will be distributing readings and
assignments on the Moodle.

\subsection{Where/When}
We meet Mondays, 1:30--3:30pm in 126 Wohler's Hall.

\subsection{Office Hours}
Thurs 1-3pm by appointment in 231 CAB or other times by
appointment. If you know in advance that you want to come to office
hours, please email me to reserve a 20 minute slot.

\section{Overview}
What does it mean to say ``statistically significant'' referring to
the outcome of a linear regression? When is it reasonable to say this?
When is it confusing?

Why can we report that a 95\% confidence interval contains some set of
plausible values for a quantity of interest? When would we mislead
ourselves and others with such claims?

In your last course you practiced fitting linear models to data and
gained the computational and conceptual foundation for answering such
questions. In this course, you will deepen your understanding of
statistical inference and estimation using linear models. This is a
course in applied statistical theory. The approach here is to work
toward understanding statistical theory by application. As such we
will emphasize the hard work of writing computer programs rather than
the hard work of proving theorems. After the hard work required by
this class you will have developed strategies for answering the
questions posed above and thus will be well-positioned to use linear
models with confidence and creativity and good judgement.

\section{Goals and Expectations}
This class aims to help you learn to think about the linear model. 

The point of the course is to position you to do the future learning
that is at the core of your work as an academic analyzing data.

I also hope that this course will help you continue to develop the
acumen as a reader, writer, programmer and social scientist essential
for your future daily life as a social science researcher.

\subsection{Expectations}
First and foremost, I assume you are eager to learn. Eagerness,
curiosity and excitement will impel your energetic engagement
with the class throughout the term. If you are bored, not curious, or
unhappy about the class you should come and talk with me
immediately. Graduate school is not the place to waste your time on
courses that are not important to you.

Second, I assume you are ready to work. Learning requires work. As
much as possible I will link practice directly to
application rather than merely as a opportunity for me to rank you
among your peers. Making work about learning rather than ranking,
however, will make our work that much more difficult and time
consuming. You will make errors. These errors are opportunities for
you to learn --- some of your learning will be about how to help
yourself and some will be about statistics. If you have too much to do
this term, then again, consider dropping the course. Graduate school
is a place for you to develop and begin to pursue your own
intellectual agendas: this course may be important for you this term,
or it may not. That is up for you to decide.

Third, I assume you are willing to go along with my decisions about
the material and sequence. I will be open to constructive and concrete
suggestions about how to teach the class as we go along, and I will
value such evaluations at any point in the class. That said, if you do
not think you need to take this course, then don't take it.

Fourth, I assume some previous engagement with high school mathematics,
probability and statistical computing in R (see,
for example, the syllabus for PS530 as taught last term).

\subsection{Rules}

There aren't many rules for the course, but they're all important.
First, read the assigned readings before you come to class.  Second,
turn everything in on time. Third, ask questions when you don't
understand things; chances are you're not alone.  Fourth, don't miss
class or section.

All papers written in this class will assume familiarity with the
principles of good writing in \citet{Beck:1986}.

All final written work will be turned in as pdf files. I will not
accept Microsoft, Apple, OpenOffice, or any other proprietary
format. Work turned in using those formats will not be looked at and
subsequent pdf files will be considered late work.

\subsection{Late Work}
I do not like evaluation for the sake of evaluation. Evaluation should
provide opportunities for learning. Thus, if you'd prefer to spend
more time using the paper assignment in this class to learn more, I am
happy for you to take that time. I will not, however, entertain late
submissions for the subsidiary paper assignments that are due
throughout the term. If you think that you and/or the rest of the
class have a compelling reason to change the due date on one of those
assignments, let me know in advance and I will probably just change
the due date for the whole class.

\subsection{Incompletes}
Incompletes are fine in theory but terrible at this university in
practice. I urge you to avoid an incomplete in this class. If you must
take an incomplete, you must give me \emph{at least} 2 months from the
time of turning in an incomplete before you can expect a grade from
me. This means that if your fellowship, immigration status, or job
depends on erasing an incomplete in this class, you should not leave
this incomplete until the last minute.

\subsubsection{Participation} 
We will be doing hands-on work nearly every class meeting. I will
lecture very little and instead will pose problems of statistical
theory, research design, and data, which will require us to confront
and apply the reading that prepared us for the day's work. I
anticipate that you'll work in small groups and that I'll circulate
and offer help when I can. I will break away to draw on the board or
demonstrate on my own computer now and then if everyone is running
into the same problem.

\subsubsection{Papers}
Other than the reading, the main assignment for this term
is for you to write a paper that assesses the
usefulness/reasonableness of the standard linear model (and associated
pre-packaged statistical inference measures) for your own work.

The ideal paper will take the pre-packaged regression table which I
presume would be the centerpiece of a paper that you wrote last term,
or which you are writing this term in some other class and would
deeply scrutinize this table using simulations and theory: do you 95\%
confidence intervals reject true null hypotheses 5\% of the time or
less? how biased are your calculations of effects/slopes and/or
standard errors? what is your target of inference? why is that target
reasonable and/or useful?

After doing this task you will be prepared to assess any other paper
you write in the future --- you will know when, how, and why your
linear model is or is not persuasive as an engine of statistical
inference.\footnote{Causal inference from the linear model will only
  be touched on in this class. But, it will be a central concern of your
  class in research design as well as the third course in this series.}


\subsection{Grades}
I'll calculate your grade for the course this way: 50\% class
involvement and participation and 50\% the paper.

Because moments of evaluation are also moments of learning in this
class, I do not curve. If you all perform at 100\%, then I will give you all
As. 

\subsubsection{Involvement}
Quality class participation does not mean ``talking a lot.''  It
includes coming to class; turning in assignments on time; thinking and
caring about the material and expressing your thoughts respectfully
and succinctly in class.

As much as possible, we will be working in groups during the class
meetings. This work will require that you have done the assigned
reading in advance and that you are an active collaborator.

% \subsubsection{Reading}
% Reading mathematical material is different from reading mostly
% words. I will try to keep the reading assigned



\subsection{Computing}
We will be using R in class so those of you with laptops available
should bring them. Of course, I will not tolerate the use of computers
for anything other than class related work during active class
time. Please install R (\url{http://www.r-project.org}) on your
computers before the first class session.

Computing is an essential part of modern statistical data analysis ---
both for turning data into information and for conveying that information
persuasively (and thus transparently and reliably) to the scholarly
community. In this course we will pay attention to computing, with special
emphasis on understanding what is going on behind the scenes. You will
be writing your own routines for a few simple and common procedures.

Most applied researchers use two or three computing packages at any
one time because no single language or environment for statistical
computing can do it all. In this class, I will be using the R
statistical language.  You are free to use other languages, although I
suspect you will find it easier to learn R unless you are
already a code ninja in some other language that allows matrix
manipulation, optimization, and looping.

As you work on your papers, you will also learn to write about data
analysis in a way that sounds and looks professional by using either a
WYSIWYG system like Word, OpenOffice, or Wordperfect, or a typesetting
system like \LaTeX, to produce documents that are suitable for
correspondence, collaboration, publication, and reproduction. No paper will be
accepted without a code appendix or reproduction archive attached (or
available to me online). No paper will be accepted unless it is in
Portable Document Format
(\href{http://en.wikipedia.org/wiki/Portable_Document_Format}{pdf}).\footnote{Actually,
  I'm willing to consider HTML or Postscript although practice with
  pdf will help you most in submitting papers to journals and other
  forms of scholarly communication.} No paper will be accepted with cut
and pasted computer output in the place of well presented and
replicable figures and tables. Although good empirical work requires
that the analyst understand her tools, she must also think about how
to communicate effectively: ability to reproduce past analyses and
clean and clear presentations of data summaries are almost as
important as clear writing in this regard.

\nobibliography*
%\nobibliography{/Users/jwbowers/Documents/BIB/trunk/big}

\section{Books}\vspace{-2em}
I'm am requiring fewer books rather than more. The readings will be
drawn from a variety of sources. I will try to make most of them
available to you as we go if you can't find them easily online yourselves.

\subsection{Required}

\bibentry{fox2008applied}.   \footnote{For additional materials and
  appendices see \url{http://socserv.socsci.mcmaster.ca/jfox/Books/Applied-Regression-2E/index.html}}

\bibentry{achen82}.


\bibentry{fox2011r}. \footnote{\url{http://socserv.socsci.mcmaster.ca/jfox/Books/Companion/index.html}}


\subsection{Recommended}
No book is perfect for all students. I suggest you ask around, look at
other syllabi online, and just browse the shelves at the library and
used bookstores to find books that make things clear to you. Here are
some recommendations:

% \bibentry{fox2002r}

% \bibentry{faraway2005lmr}

% \bibentry{faraway2006elm}

% \bibentry{verzani2005uri}

% \bibentry{kaplan2009ism}

% \bibentry{fpp07}

% \bibentry{gonick1993cgs}

% \bibentry{berk04}

% \bibentry{rice2007msd}

% \bibentry{trosset2009isi}

% \bibentry{gelman2007dau}

% \end{introstuff}

% \bibliography{/Users/jwbowers/Documents/BIB/trunk/big}

\paragraph{Books much like \cite{fox2008applied} with slightly
  different emphases and more R in the text:}

\bibentry{gelman2007dau}.\footnote{\url{http://www.stat.columbia.edu/~gelman/arm/}}
This book has a really nice few chapters on causal inference and on
post-estimation model exploration and interpretation as well as many
excellent chapters on multilevel models.

\bibentry{lancaster2004introduction}. This book is a nice introduction
to Bayesian inference (in addition to Gelman and Hill, which is also an
introduction to Bayesian inference without being as explicit about
it). Come and talk with me if you'd like pointers to more of the
Bayesian literature.

\bibentry{trosset2009isi}. This book represents a nice modern take on
what you'd learn in your first or second course in a statistics
department. The linear model plays a relatively small role. However,
the coverage of frequentist theory is very nicely done.

\paragraph{If you'd like books that more closely link the statistics
  with R:}

\bibentry{faraway2005lmr}

\bibentry{faraway2006elm}

\bibentry{verzani2005uri}

\paragraph{If you'd like different perspectives on the material and
  perhaps a bit less math I \emph{highly} recommend the following
  books. I love them!}

These books are particularly good to help you get clear on the
fundamental concepts of statistical inference: what it means to test a
hypothesis, construct a confidence interval, etc...

\bibentry{berk04}

\bibentry{fpp07}

\bibentry{gonick1993cgs}

\bibentry{kaplan2009ism}\footnote{\url{http://www.macalester.edu/~kaplan/ism/}}

\paragraph{If you'd like more math and theory try these:}

\bibentry{Cox:2006}. This is one of my favorite books on statistical
theory at the moment.

\bibentry{rice2007msd}. This is commonly assigned for first year
statistics ph.d. students.

\bibentry{greene97} (Or any edition of Greene.). This is commonly
assigned for first year economics ph.d. students.

\bibentry{angrist2009mostly}

\bibentry{kennedy2003guide} Other editions of this surely exist.

\paragraph{Math books}

You should also have at least one math book on your shelves. Some
general recommendations for books that combine linear algebra and
calculus among other topics:

\bibentry{chiang}

\bibentry{fox2008mathematical}

\bibentry{gill2006essential}

\bibentry{simon94}

\paragraph{Self-Help}
If you discover any books that are particularly useful to you, please
alert me and the rest of the class about them. Thanks!

\section{Schedule}

\textbf{Note: } This schedule is preliminary and subject to change. If
you miss a class make sure you contact me or one of your colleagues to
find out about changes in the lesson plans or assignments.

The idea behind the sequencing here is to start as simple as possible
and complicate later. Many of you have already been ``doing
regression'' and this class exists to help you understand more deeply
what you are doing --- to give you power over your tools, to enable
creativity, flexibility, and, at minimum, to help you avoid errors.

This class emphasizes the linear model. There are mathematically
simpler ways to introduce the concepts and techniques of statistical
inference, but you are already using linear models and you'll continue
to use them throughout your careers (where linear models include
linear regression, logit, probit, poisson, multinomial logit,
etc..). Since this class aims to help you do work and privileges such
doing over deep theory, and since this is your second course, we'll
thus focus on the mathematically and conceptually more complex but
more commonly used linear model.

\textbf{Data: } I'll be bringing in data that I have on hand. This
means our units of analysis will often be individual people or perhaps
political or geographic units, mostly in the United States. I'd love
to use other data, so feel free to suggest and provide it to me ---
come to office hours and we can talk about how to use your favorite
datasets in the class.

\textbf{Theory: } This class is about statistical inference and thus
statistical theory. Yet, statistics as a discipline exists to help us
understand more than why the linear model works as it does. Thus,
social science theory cannot be far from our minds as we think about
what makes a given data analytic strategy meaningful. That is, while
we spend a term thinking a lot about how to make meaningful statements
about statistical inference, we must also keep substantive
significance foremost in our minds.


\end{introstuff}

\SetDate[24/01/2011]
\part{General Principles for Frequentist Statistical Inference:
  Randomize, Repeat, Reject}

The first section of the class focuses as directly as possible on the
foundations of statistical inference for the linear model. We need to
know the target of our inference, and why we might be justified in
inferring to such a target.\footnote{\citet{cobb2007introductory}
  provided the ``randomize, repeat, reject'' motto and otherwise
  articulates some of the inspiration for this course.} It turns out
that computers make the job of doing such inference much easier, but
in committing to computation we'll have to learn a bit more math so
that we can communicate most effectively with our computers as they
make our lives easier.

\section{1 --- \today --- What is the linear model for? }
% \section{\today---Why the linear model? What is statistical
%   inference? How to do it?}

\subsection{Reminder:} Bring laptops if you have them. Those bringing
laptops should have R installed or be able to access their Rstudio
accounts and be able to access the net.

\subsection{Topics:} Review of the bivariate linear model; Linear
model as description using smoothed conditional means; Uses of the the
linear model (description, forecasting, statistical inference, causal
inference); Dummy variables; Differences of means; Predicted values;
Residuals; Linearity assessment.

% How can we figure out and communicate the effect of an experimental
% treatment on an outcome? How would a linear model be useful for this
% purpose?

% How do we tell a computer to fit a line to data?

% Linear model to get difference of means. (in class).

% What is a \emph{reasonable guess} about this effect? How can we
% defend the claim that our guess is reasonable?
% [confounding/ommittted variables; also about linearity and
% globality; claims no important outliers; no unduly influential
% points]

% Why guess? [to describe, to predict, to infer to what could be
% directly observed with enough work (statistical inference), to infer
% to what can never be observed directly (causal inference)]

% How to assess the reasonable ness of the guess? [scatter plots of
% residuals, nonlinearity etc.., a bit on potentially influential
% points]

% Gelman and Hill Chap 3 (overview) for later
\subsection{Read:}
\textbf{Henceforth, ``*'' means ``recommended'' or ``other useful''
reading. The readings not marked with ``*'' are required.}

\citealp[Chapters 1,2,5.1]{fox2008applied} %Fox Chap 1,2,5.1

\citealp[Pages
1--8]{berk2008statistical}\footnote{\url{http://www.library.uiuc.edu/proxy/go.php?url=http://dx.doi.org/10.1007/978-0-387-77501-2}}

*\citealp[Chapter 1--3]{berk04}


\subsection{Do:} \textbf{``Do'' means, ``do in class.'' I am writing
  down sketches about what we might do in class so that you might be
  thinking about these tasks as you read.}

Practice the linear model and prove to selves that a linear model with
dummy variables tells us something about a difference of means and
that the proposed computational technique does minimize the sum of
squared residuals. Consider and explore other ways to summarize the
conditional distribution of an outcome on an explanatory variable
(summaries of ranks? quantiles? something else?).

%\subsection{Admin:}
%Possibly three conflicts: March 31 for MPSA and April 15 for SLAMM.
 
%\begin{com}
%  Consider rescheduling April 2 for the Soc Methods meetings, April 16
%  for SLAMM, and April 23 for MPSA. Yuck! Why am I on a Friday anyway?
%\end{com}

\AdvanceDate[7]
\section{2---\themonth~\the\day---What is a hypothesis test?} %January 26 ---

How much evidence does some data summary provide against a
substantively relevant hunch about the process under study? How can we
formalize and communicate the plausibility of such hunches in light of our observation?

\subsection{Topics:} Two bases out of at least three bases for
frequentist statistical inference (random assignment, random
sampling); randomization distributions and sampling distributions of
test statistics. Today focus on random assignment and randomization
distributions of test statistics under the sharp null hypothesis of no
relationship. Generating randomization distributions for hypotheses
about aspects of the linear model using enumeration (aka permutation)
and simulation (shuffling). Introduction to significance level of a
test versus size of a test.

\subsection{Read:}
\citealp[Chap 15,16.1,16.6,16.7,17.5,17.7,17.8]{kaplan2009ism} discusses tests of hypotheses in the
context of permutation distributions of linear model based test
statistics. He wants to emphasize the $F$-statistic and $R^2$ and the
ANOVA table, but his discussion of permutation based testing will
apply to our concern with the effect of an experimental treatment on an outcome.

\citealp[Chap 8]{gonick1993cgs} explains the classical approach to
hypothesis testing based on Normal and $t$-distributions.

\citealp[Chap 5]{imbens2009causal} explains Fisher's approach to the
sharp or strict null hypothesis test in the context of the potential
outcomes framework for causal inference.

*\citealp[Chap 4]{berk04} provides an excellent and readable overview
of the targets of inference and associated justifications often used
by social scientists.

% \subsection{Other Useful Reading}
*\citealp[Chap 21.4]{fox2008applied} explains about bootstrap hypothesis tests
(i.e. sampling model justified hypothesis tests).  

*\citealp[Chap 2]{fisher:1935} explains \emph{the} invention of
random-assignment based randomization inference in about 15 pages with
almost no math.

*\citealp[Chap 2--2.4]{rosenbaum:2002} explains and formalizes Fisher's randomization inference.

*\citealp{rosenbaum:2002a} explains how one might use Fisher-style
randomization inference with linear regression.

\subsection{Do:} TBA

\AdvanceDate[7]
\section{3---\themonth~\the\day---What is a confidence interval? }
Given a reasonable data summary, what other guesses about said
quantity are plausible?

% Notice: we assessed plausility last week with the p-value. So, what
% we really want is the set of hypothesis not rejected. [talk about
% rejection and acceptance etc..]

\subsection{Topics} Continuing on statistical inference; Inverting
hypothesis tests; null hypotheses and alternatives; Introduce the weak
null and the average treatment effect; The bootstrap; Today focus on
sampling models for statistical inference but link back to assignment
models via hypothesis test inversion. More on concepts of
level of test versus size of test, Type I and Type II errors, power of tests.

\subsection{Read:}
\citealp[Chap 14]{kaplan2009ism} 

\citealp[Chap 7]{gonick1993cgs}

\citealp[Chap 21]{fox2008applied}

*\citealp[Chap 6]{imbens2009causal} discusses and compares Fisher's
approach to Neyman's approach. We will defer discussion about the the parts of the
discussion regarding Normality until later in the course. Review their
chapter 5.8 for discussion about inversion of the hypothesis test to
create confidence intervals.

*\citealp{neyman:1923,rubin1990apt} \emph{the} invention of
random-sampling based randomization inference.

*\citealp[Chap 2.7]{lohr:1999} a clear exposition of the
random-sampling based approach.

\subsection{Do:} TBA. Notice some of the limitations
of the each computational approach to generating confidence intervals:
the sampling model as approximated by the bootstrap has problems with
small samples (introduce ideas about collinearity and efficiency); the
assignment model as approximated with shuffling (or enumeration)
becomes computationally expensive. Both require models of effects.

\subsection{Due:} First round of regression tables (or sketches
thereof) for the final paper. The substantive topic addressed by your
tables should be pretty fascinating and important to you so as to buoy
your interest and energy for the rest of the term.

\AdvanceDate[7]
\section{4---\themonth~\the\day---``Controlling for'' and ``Holding Constant'': Statistical and
  Stratification.}

For the next three classes we step away from statistical inference and
talk more about causal inference and explanation (and computation) as
we engage with multiple regression.

\subsection{Topics:} Confounding/Omitted variable bias; Efficiency of
linear model estimators; Extrapolation/Interpolation;
``Post-treatment'' or intermediate variables versus covariates;
Post-stratification versus residualization; Specification issues
including collinearity and continuing engagement with
dummy/categorical covariates variables; introduce interaction terms as
a way to do stratification.

\subsection{Read:}
\citealp[Chap 5.2]{fox2008applied} (multiple regression scalar form).

\citealp[Chap 6--7]{berk04} (skipping stuff on standardized coefs)

\citealp[Chap 9.0--9.2]{gelman2007dau} (on causal inference)

*\citealp[Chap TBA]{handj77} (more on multiple regression in scalar form)

*\citealp[Chap 8,10,11]{kaplan2009ism} (on a geometric interpretation of residualization)

\subsection{Do:} TBA; write a program to fit a least squares line as
if you only knew the scalar form; interpret the results of a
regression ``holding constant'' via residualization versus
stratification.

\subsection{Due:} Second round of regression tables. By now you should
know what regression results you aim to investigate for the rest of
the term.

\AdvanceDate[7]
\section{5---\themonth~\the\day---How can we compute reasonable guesses without
  fuss? (try matrices).}

%\subsection{Note:} Meet from 1--3pm rather than 1:30--3:50pm to enable
%us to attend the Hibbing talk.

\subsection{Topics:} Basic matrix algebra (also called ``linear
algebra'') [matrices and vectors introduced; addition, subtraction,
multiplication, transposition and inversion]; Matrix algebra of the
linear model (the importance and meaning and source of $\bX \hat{\bbeta}$ and
$(\bX^{T}\bX)^{-1} \bX^{T}\by$); Matrix algebra for estimating and
interpreting the linear model in R; More engagement with collinearity
and dummy variables.

\subsection{Read:}
\citealp[Appendix B.1.0--B.1.3 and Chap 9]{fox2008applied} 

*\citealp[Chap 10]{fox2008applied} (another geometric interpretation)

*\citealp[Appendix B]{fox2008applied} (more on matrices)

\subsection{Do:} Explain, explore and unpack the function we've been
using to produce slopes. What limitations on the $\bX$ matrix are
required by the least squares criterion? How might we manage
them. Prove to ourselves that our functions work.

\AdvanceDate[7]
\section{6---\themonth~\the\day---Challenges to reasonable guessing/description
  and inference: Overly Influential points and Overly (Multi)Collinear
  predictors.}

\subsection{Topics:} Influence, Leverage, Hat Matrix; Methods for
handling highly influential points; Methods for handling overly
multicollinear predictors.

\subsection{Read:}
\citealp[Chap 11]{fox2008applied} on Overly Influential Points 

\citealp[Chap 13]{fox2008applied} on Overly (Multi)Collinear predictors.

*\citealp{ache:02} (on why kitchen sink regression are a problem)

*\citealp[Chap 7]{fox2008applied} on a common case of collinearity:
categorical predictors/dummy variables

*\citealp[Chap 19]{fox2008applied} on making linear models resistant to overly influential points.

\AdvanceDate[7]
\section{7---\themonth~\the\day---Inference for combinations of
  predictors.}


\subsection{Topics:} Interaction terms; Constrained linear regression
and linear contrasts; $F$-tests, Wald-type-tests and
related confidence regions; Inference for predictions; Goodness of fit
(part 1) ($R^2$ and standard error of the regression). Understanding
more about the algebra of expectations/variances.

\subsection{Read:}
\citealp[Chap 5.2.3,7, 8.5]{fox2008applied} (on $R^2$ and dummy variables and interactions)

\citealp[Chap 16]{kaplan2009ism} (on $F$-tests and $R^2$)

TBA for more on $R^2$ and goodness of fit.

*\citealp{BramClarGold:2006} (on large-sample based approach for interaction terms)


\part{Connections to Large-Sample Statistical Theory}

When we don't have the time for our computers to do the ``repeat''
phase of ``randomize, repeat, reject'', what can we do? Luckily for
us, the mathematical underpinning of ``repeat'' after ``randomize''
has been well developed. It is this foundational mathematics that
enables the standard regression table to exist (you know, the one that
you get when you type \texttt{summary(myregression)} in
R). Much of the time this table is an excellent approximation
to what we did with repetitive computing in the previous section of
the course. Sometimes it is a terrible approximation. This part of the
course aims to connect the computationally intensive but conceptually
clear and mathematically simple theory that we learned and applied
above to the computationally simple but mathematically complex theory
that provides most of the information social scientists currently use
from linear models.

Since we have little time, we will not do proofs; instead we will
convince ourselves that the mathematicians and statisticians working
between roughly 1690 and 1940 invented reasonable approximations using
simulations. More importantly, we'll learn how to
evaluate when those analytic results help us and when they do
not.

% 1690
% (Bernoulli), 1720 (DeMoivre), 1748 (Euler), 1809 (Gauss), 1909
% (Gossett), and were correct.


% (starting at least around 1690 and 1720 with Bernoulli and DeMoivre
% and continuing through LaPlace and Gauss 1790s--1820s and at least
% through Gossett (aka Student) around 1910).



\AdvanceDate[7]
\section{8---\themonth~\the\day---The Mathemagic of Sums.}

\subsection{Topics:} Foundations of the large-sample theory: laws of
large numbers and central limit theorems; more explanation for the
pervasiveness of the mean as a data summary. Approximation.

\subsection{Reading:}
\citealp[Chap 16--18]{fpp07} (especially Chapter 18)

TBA from Rice?

*\citealp[Chap 8]{trosset2009isi}

*\citealp[Chap 2.7--2.8]{lohr:1999} Recall the use of a sampling
theory approach requiring the Central Limit Theory and compare to an approach
positing a distribution for outcomes.

\subsection{Do:} Prove to ourselves that one Central Limit Theorem and
one Law of Large Numbers actually works; Show how we can approximate
our simulation based results very well (or very badly) using this mathemagic.

%\AdvanceDate[7]
%\AdvanceDate[7]
\SetDate[21/03/2011]
\section{\themonth~\the\day---Spring Break}

\SetDate[28/03/2011]
\section{9---\themonth~\the\day---Sampling based Large sample/Asymptotic theory
  for the linear model.}

\subsection{Topics:} Gauss-Markov theorem and associated classic
linear model assumptions (introducing notions of non-constant
variance, dependence); The different roles of Normality in the theory
of the linear model; The $t$-distribution and $t$-test; the
$F$-distribution and $F$-test; The usefulness of the large sample
theory in flexible interpretation and assessment of the linear model
(i.e. the ease of simulation from the implied sampling distribution of
the coefficients).

\subsection{Read:}
\citealp[Chap 6,9]{fox2008applied} 

\citealp{achen82}

\citealp[Chapter 4,6]{berk04}

\citealp[Chap 7]{gelman2007dau} (using the large sample theory to
interpret and assess the linear model)

*\citealp[Chap 9]{trosset2009isi} (not about the linear model, but nice
on large sample hypothesis testing in general)

*\citealp[Chap 12]{fox2008applied} (on approaches to adjusting for
violations of the large-sample theory assumptions. (WLS, GLS)

\subsection{Do:} Design simulations to assess how well the
large-sample theory approximates the simulation based results in some
common datasets and designs. Begin to develop some intuitions for when
the standard regression table is fine and when it is worrisome. Notice
how useful these results are in research design (before we can collect
data we cannot shuffle or re-sample). Discuss how we might design
studies to enhance statistical inference. Notice the role of
assumptions --- especially the additional assumptions.


% Notice: Adding assumptions about constant variance and that the CLT is
% working. Maintaining previous assumptions about independence and
% linearity (i.e. reasonableness of the description) and, for causal
% interpretation, assumptions about lack of ommitted variable bias. (see
% Fox 12 on some corrections to the approximations useful when the
% direct approaches appear difficult)

\AdvanceDate[7]
\section{10---\themonth~\the\day--- A general, large sample, based approach to
  making reasonable guesses: Maximum Likelihood for the linear model.}

Frequentists make inferences to control groups based on experimental
design (following Fisher), to a population based on sampling design
(following Neyman). They also make inferences to \emph{a model of the
  population} often called a \emph{data generating process}. Such
models are at the core of the likelihood approach to statistical
inference (also credited to Fisher).

\subsection{Topic:} A third frequentist mode of inference; Role of the
central limit theorem and Normality in this approach; OLS is MLE; MLE
as useful for binary outcomes in addition to continuous outcomes.

\subsection{Read:}
\citealp[Chap 9.3.3]{fox2008applied} 

\citealp[Chap 18.1--18.3]{gelman2007dau} (skimming over the stuff
about Bayes, Gibbs sampling, etc...)

*TBA from \citet{rice2007msd} or other more canonical and mathematical
treatments

*\citealp[Chap 4]{king89}

*\citealp[Chap 1,2]{Cox:2006}


\subsection{Do:} Re-estimate our linear models using our own
likelihood maximizing function (first by examining the profile
likelihood function graphically and second by asking the computer to
find the maximum). Plug in a Bernoulli likelihood and
explore use with binary outcomes. Assess the statistical inferences
from MLE compared to those arising from shuffling and/or bootstrapping
(or enumerating, or even Normal approximations to the shuffles). 

% Notice: Allows you to use information not in the design (i.e. that the
% data generating process was Poisson, or Binomial, etc..) Show for
% Normal and Poisson or Binomial.

% Notice: Very flexible and general (thus, is the theory behind logit
% and probit, survival analysis, time-series analysis, and many other
% such approaches)


\subsection{Due:} A plan for your final paper specifying why the
regression table you chose is substantively meaningful; your
simulation and assessment plans; plans for tables and/or figures; and
your plans for producing reproducible analyses.

\part{Dependent Observations and Causal Inference: Challenges to Statistical Inference} %Gelman and Hill
% ?Hansen and Bowers? ?Small et al?

The previous sections have prepared us to engage with some of the more
realistic designs used by political scientists: designs in which each
row in the dataset is related to other rows by design. Recall that we
had to make assumptions about independence whether we used simulations
or large-sample theory. Here we engage with some of the ways that one may
handle dependent research designs, and perhaps, at the end, introduce
the topic of dealing with missing data. Thus, this course ends with
some very real-world situations in which we desire statistical
inferences (let alone causal inference) but that challenge the simple
methods of justifying said inferences.

\AdvanceDate[7]
\section{11---\themonth~\the\day---Difference-in-Differences/Before-After Designs}
One of the simplest ways we might violate independence assumptions is
when we want to strengthen causal inference by observing the same unit
twice (perhaps both before and after some event/intervention/change). 

\subsection{Topics:} Back to causal inference --- Consider benefits of
observing each unit twice; Consider difficulties for statistical
inference posed by observing each unit twice; Consider solutions;
Generalized Least Squares (GLS) and ``cluster-robust'' or
``heteroskedasticity consistent'' methods.

\subsection{Read:}
\citealp{bertrand2004msw}

\citealp{allison1990change}

\citealp[Chap 10.7]{gelman2007dau} (on longitudinal designs.)

*\citealp[Chap 9--10]{gelman2007dau} (on causal inference including some discussion of instrumental variables.)

*TBA something from Campbell and Stanley on the strengths and
weaknesses of such designs.

\subsection{Do:} Assess the usefulness of the strategies of (a)
ignoring dependence [?how badly mislead might we be? what simple
strategies might we use? (remember the advice in \citet{achen82})] and
(b) the corrections proposed above using our simulation based methods
that we developed earlier in the course.


\subsection{Due:} A proposal for assessing the properties of your
regression table.

\AdvanceDate[7]
\section{12---\themonth~\the\day---Corrections for unstructured dependence
  (multilevel/longitudinal designs part 1)}

The first set of approaches to multilevel designs (which include some
panel designs, measurement models, etc..) focuses on correcting the
statistical inferences from models estimated ignoring the
dependence.

\subsection{Topics:} Huber/White/ ``cluster-robust'' standard errors;
Issues arising with causal and statistical inference from multilevel designs.

\subsection{Read:}
\citealp[Chap 12]{fox2008applied} (especially 12.2)

\citealp{LongErvi:2000} (on the general idea of estimating a model while
ignoring dependence and then correcting some piece of that model.)

\citealp{wooldridge2003csm} (on the block-diagonal variance-covariance
matrix methods (``cluster robust'') types of corrections.)

\citealp{Free:2006:On-t} (for some criticism of these kinds of methods.)

*\citealp{cribarineto2004aiu} (on other methods for making the simple
correction and problems arising from the initial ideas of Huber and White.)

*\citealp{green2007acr} (for an exemplar of using simulation to check the performance of such methods in some particular designs.)

*\cite{faes2009effective} (on different conceptions of what ``degrees of
freedom'' and ``sample size'' might mean in a complex design)

\subsection{Do:} Explore and discover how many cluster/groups is
enough for us to trust that confidence intervals based on this
type of method have good coverage.

\AdvanceDate[7]
\section{13 ---\themonth~\the\day---Instrumental Variables}

\subsection{Topics:} The potential outcomes approach to causal
inference; causal inference in a randomized experiment; causal
inference with instruments.

\subsection{Read:}
\citealp{Angrist:etal:1996}

\citealp{dunning2008model}

\citealp{sovey2011instrumental}

\citealp[Chap 10.4--10.5]{gelman2007dau} (you might also want to revist their Chap 9 and previous part of Chap 10).

*\citealp{ImbRos:2005:Robu} On weak instruments

*\citealp{angrist2009mostly}[Chapter 4]

\subsection{Do:} Work on understanding the requirements of an
instrumental variable and their use in statistical inference. Perhaps
discuss the dilemma of weak instruments.


% \section{13 ---\themonth~\the\day---Modeling unstructured dependence
%   (multilevel/longitudinal designs part 2)}


% A second set of approaches to multilevel designs attempts to directly
% model the dependence. When people talk about ``multilevel models''
% this is the approach they to which they refer.

% \subsection{Topics:} What does it mean to model both outcomes and
% parameters?; A taste of Bayes; Comparisons of full parametric models
% versus the corrections considered above; More on interaction terms
% (cross-level interactions) and likelihood.

% \subsection{Read:}
% \citealp[Chap 11--13]{gelman2007dau} 

% \citealp{BoweDrak:2005} on alternative graphical and exploratory methods

% *\citealp[Chap 16,21,23--24]{gelman2007dau} on fitting, checking, and interpreting multilevel models.

% \subsection{Do:} Make some of the graphs suggested in
% \citet{BoweDrak:2005,gelman2007dau}; fit, check and interpret some
% multilevel models. Assess these models using predictive posterior
% checks as well as against the design based approaches developed
% earlier in the course. Consider the target of inference for multilevel
% models versus for other approaches to dependence.

% \subsection{Due:} Progress reports on final paper.

\AdvanceDate[7]
\section{14 ----\themonth~\the\day---Matching and Poststratification}

\subsection{Topics:} Matching is a nonparametric way to compare like
with like. Although there are many kinds, since we only have one day we
will focus on post-stratification --- a kind of matching that does not
repeat units and that thus enables more or less conventional
statistical inference for causal effects after matching is complete.

\subsection{Read:}
\citealp{rosenbaum2010design}[Chap 3, 7--13]

\citealp{hansen:2004a}

\citealp{lu2011optimal}



\subsection{Do:} Practice producing matched sets, assessing balance,
assessing causal effects.


% \subsection{Topics:} Today we'll engage with questions about
% statistics and statistical inference that have lingered from the
% previous parts of the term or perhaps that have come up in other
% contexts or perhaps questions that have arisen as you've worked on
% your papers. So send me your questions and I'll try to organize them
% and think about them.

% \subsection{Read:} Depends on the questions.
% \section{14---\themonth~\the\day---Missing Data as a threat to
%   Description, Statistical Inference, and Causal Inference.}

% \subsection{Topics:} Distinctions among types of missing data and
% potential problems caused by the different types; Approaches to
% missing data on outcomes versus on covariates versus on key causal
% variables.

% \subsection{Read:}
% \citealp[Chap 20]{fox2008applied}.

% *\citealp[Chap 25]{gelman2007dau}

% \subsection{Do:} Prove to ourselves that (1) non-random missing data
% on covariates is an efficiency problem, (2) non-random missing data on
% outcomes and/or key explanatory (aka causal) variables is a bias
% \emph{and} efficiency problem.

\AdvanceDate[7]
\section{\themonth~\the\day---Final Papers Due}

\part{References}
%\bibliography{/Users/jwbowers/Documents/BIB/big}
\bibliography{thesyllabus}

\end{document}

